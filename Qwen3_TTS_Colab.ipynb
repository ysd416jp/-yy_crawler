{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Qwen3-TTS — 無料ボイスクローン & 音声生成\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ysd416jp/-yy_crawler/blob/claude/mobile-tts-system-JEkXZ/Qwen3_TTS_Colab.ipynb)\n\nAlibaba Qwen3-TTS を Google Colab の無料 GPU (T4) で動かします。\n\n**主な機能:**\n- **ボイスクローン**: mp3/wavをアップ → 日本語テキストを打つ → その声で喋る\n- **TTS**: プリセット音声でテキスト読み上げ\n- **ボイスデザイン**: 自然言語で声質を指定して生成\n\n## スマホからの使い方（3ステップ）\n\n1. 「ランタイム」→「ランタイムのタイプを変更」→ **T4 GPU** を選択\n2. 「ランタイム」→「**すべてのセルを実行**」をタップ\n3. 最後のセルに表示される `https://xxxxx.gradio.live` のURLをタップ → 完了!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU確認 & インストール\n",
    "\n",
    "「ランタイム」→「ランタイムのタイプを変更」→ **T4 GPU** を選択してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# GPU確認\n!nvidia-smi\nprint(\"\\n\" + \"=\"*60)\n\nimport torch\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    print(f\"GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n    print(\"OK: GPUが利用可能です\")\nelse:\n    print(\"WARNING: GPUが見つかりません。\")\n    print(\"「ランタイム」→「ランタイムのタイプを変更」→ T4 GPU を選択してください\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Qwen3-TTS と関連パッケージをインストール\n!pip install -U qwen-tts gradio soundfile numpy -q\n\nprint(\"\\nインストール完了\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. モデル設定\n",
    "\n",
    "**モデルサイズを選択:**\n",
    "- `0.6B`: 軽量・高速。無料T4で余裕で動く\n",
    "- `1.7B`: 高音質。無料T4 (16GB) でも動作可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title モデルサイズ選択 { run: \"auto\" }\n",
    "MODEL_SIZE = \"1.7B\"  #@param [\"0.6B\", \"1.7B\"]\n",
    "\n",
    "print(f\"選択: {MODEL_SIZE} モデル\")\n",
    "if MODEL_SIZE == \"1.7B\":\n",
    "    print(\"高音質モード。ダウンロードに数分かかります。\")\n",
    "else:\n",
    "    print(\"軽量モード。高速に起動します。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. モデル読み込み\n",
    "\n",
    "初回実行時はモデルのダウンロードが入ります（数分）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nfrom qwen_tts import Qwen3TTSModel\nimport soundfile as sf\nimport numpy as np\nimport os\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float16\n\n# FlashAttention 2: Ampere (compute capability 8.0) 以降のGPUのみ対応\n# T4 は Turing (7.5) なので使えない → SDPA を使用\nattn_impl = \"sdpa\"\nif torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:\n    try:\n        import flash_attn\n        attn_impl = \"flash_attention_2\"\n        print(\"FlashAttention 2: 有効 (Ampere GPU)\")\n    except ImportError:\n        print(\"FlashAttention 2: 未インストール → SDPA使用\")\nelse:\n    print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n    print(f\"FlashAttention 2: 非対応GPU → SDPA使用（問題なし）\")\n\nprint(f\"Device: {device}, Dtype: {dtype}, Attention: {attn_impl}\")\nprint(f\"\\n--- CustomVoice モデル読み込み中... ---\")\n\n# CustomVoice: プリセット音声でTTS\nmodel_custom = Qwen3TTSModel.from_pretrained(\n    f\"Qwen/Qwen3-TTS-12Hz-{MODEL_SIZE}-CustomVoice\",\n    device_map=device,\n    dtype=dtype,\n    attn_implementation=attn_impl,\n)\nprint(\"CustomVoice OK\")\n\nprint(f\"\\n--- Base モデル読み込み中... ---\")\n\n# Base: ボイスクローン\nmodel_base = Qwen3TTSModel.from_pretrained(\n    f\"Qwen/Qwen3-TTS-12Hz-{MODEL_SIZE}-Base\",\n    device_map=device,\n    dtype=dtype,\n    attn_implementation=attn_impl,\n)\nprint(\"Base OK\")\n\n# VoiceDesign: 1.7Bのみ\nmodel_design = None\nif MODEL_SIZE == \"1.7B\":\n    print(f\"\\n--- VoiceDesign モデル読み込み中... ---\")\n    model_design = Qwen3TTSModel.from_pretrained(\n        \"Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign\",\n        device_map=device,\n        dtype=dtype,\n        attn_implementation=attn_impl,\n    )\n    print(\"VoiceDesign OK\")\n\n# VRAM確認\nif torch.cuda.is_available():\n    allocated = torch.cuda.memory_allocated() / 1024**3\n    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    print(f\"\\nVRAM: {allocated:.1f} / {total:.1f} GB\")\n\nprint(\"\\n全モデル読み込み完了\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradio UI 起動\n",
    "\n",
    "実行すると公開 URL が表示されます。  \n",
    "その URL をスマホで開けば、どこからでも使えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import gc\nimport json\nimport random\nimport re\nimport gradio as gr\nimport soundfile as sf\nimport numpy as np\nimport tempfile\nimport os\n\n# ==================================================\n# モデル状態リセット（2回目以降の生成で音声が破綻する問題の修正）\n# ==================================================\ndef _reset_model_state(model):\n    \"\"\"生成間で残留する内部状態をクリアし、2回目以降の音声破綻を防ぐ。\"\"\"\n    inner = getattr(model, \"model\", None)\n    if inner is None:\n        return\n    if hasattr(inner, \"rope_deltas\"):\n        inner.rope_deltas = None\n    if hasattr(inner, \"generation_step\"):\n        inner.generation_step = -1\n    if hasattr(inner, \"past_hidden\"):\n        inner.past_hidden = None\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    gc.collect()\n\n\ndef _set_seed(seed):\n    \"\"\"乱数シードを固定して再現性のある生成を行う。\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n\ndef _sampling_kwargs(temperature, top_p):\n    \"\"\"サンプリングパラメータの dict を返す。\"\"\"\n    return dict(\n        temperature=temperature,\n        top_p=top_p,\n        top_k=50,\n        repetition_penalty=1.0,\n        subtalker_temperature=temperature,\n        subtalker_top_p=top_p,\n        subtalker_top_k=50,\n    )\n\n\n# ==================================================\n# 読み替え辞書\n# ==================================================\nDICT_PATH = \"tts_dictionary.json\"\n\ndef _load_dictionary():\n    if os.path.exists(DICT_PATH):\n        with open(DICT_PATH, encoding=\"utf-8\") as f:\n            return json.load(f)\n    return {}\n\ndef _save_dictionary(dic):\n    with open(DICT_PATH, \"w\", encoding=\"utf-8\") as f:\n        json.dump(dic, f, ensure_ascii=False, indent=2)\n\ndef _apply_dictionary(text):\n    dic = _load_dictionary()\n    if not dic:\n        return text\n    pattern = re.compile(\"|\".join(re.escape(k) for k in sorted(dic, key=len, reverse=True)))\n    return pattern.sub(lambda m: dic[m.group()], text)\n\n\n# プリセット音声リスト\nSPEAKERS = [\"Vivian\", \"Serena\", \"Uncle_Fu\", \"Dylan\", \"Eric\", \"Ryan\", \"Aiden\", \"Ono_Anna\", \"Sohee\"]\n\nLANGUAGES = {\n    \"日本語\": \"Japanese\",\n    \"英語\": \"English\",\n    \"中国語\": \"Chinese\",\n    \"韓国語\": \"Korean\",\n    \"ドイツ語\": \"German\",\n    \"フランス語\": \"French\",\n}\n\n# ボイスクローン用プロンプトキャッシュ\n_clone_prompt_cache = {\"ref_audio\": None, \"ref_text\": None, \"prompt\": None}\n\n\ndef voice_clone(text, language, ref_audio, ref_text, temperature, top_p, seed):\n    \"\"\"参照音声からクローン生成\"\"\"\n    if not text.strip():\n        raise gr.Error(\"読み上げテキストを入力してください\")\n    if ref_audio is None:\n        raise gr.Error(\"参照音声(mp3/wav)をアップロードしてください\")\n    if not ref_text.strip():\n        raise gr.Error(\"参照音声のテキスト（何と言っているか）を入力してください\")\n    try:\n        _reset_model_state(model_base)\n        if seed >= 0:\n            _set_seed(int(seed))\n        text = _apply_dictionary(text)\n        lang = LANGUAGES.get(language, \"Japanese\")\n        kwargs = _sampling_kwargs(temperature, top_p)\n        # 同じ参照音声ならプロンプトを再利用（声質の安定性向上）\n        if (_clone_prompt_cache[\"ref_audio\"] != ref_audio\n                or _clone_prompt_cache[\"ref_text\"] != ref_text):\n            _clone_prompt_cache[\"prompt\"] = model_base.create_voice_clone_prompt(\n                ref_audio=ref_audio, ref_text=ref_text,\n            )\n            _clone_prompt_cache[\"ref_audio\"] = ref_audio\n            _clone_prompt_cache[\"ref_text\"] = ref_text\n        wavs, sr = model_base.generate_voice_clone(\n            text=text,\n            language=lang,\n            voice_clone_prompt=_clone_prompt_cache[\"prompt\"],\n            **kwargs,\n        )\n        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n        sf.write(tmp.name, wavs[0], sr)\n        return tmp.name\n    except Exception as e:\n        raise gr.Error(f\"エラー: {e}\")\n\n\ndef tts_generate(text, speaker, language, temperature, top_p, seed):\n    \"\"\"プリセット音声で読み上げ\"\"\"\n    if not text.strip():\n        raise gr.Error(\"テキストを入力してください\")\n    try:\n        _reset_model_state(model_custom)\n        if seed >= 0:\n            _set_seed(int(seed))\n        text = _apply_dictionary(text)\n        lang = LANGUAGES.get(language, \"Japanese\")\n        kwargs = _sampling_kwargs(temperature, top_p)\n        wavs, sr = model_custom.generate_custom_voice(\n            text=text,\n            language=lang,\n            speaker=speaker,\n            **kwargs,\n        )\n        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n        sf.write(tmp.name, wavs[0], sr)\n        return tmp.name\n    except Exception as e:\n        raise gr.Error(f\"エラー: {e}\")\n\n\ndef voice_design(text, language, instruct_text, temperature, top_p, seed):\n    \"\"\"自然言語で声質を指定して生成\"\"\"\n    if model_design is None:\n        raise gr.Error(\"VoiceDesignは1.7Bモデルのみ対応です\")\n    if not text.strip():\n        raise gr.Error(\"テキストを入力してください\")\n    if not instruct_text.strip():\n        raise gr.Error(\"声質の説明を入力してください\")\n    try:\n        _reset_model_state(model_design)\n        if seed >= 0:\n            _set_seed(int(seed))\n        text = _apply_dictionary(text)\n        lang = LANGUAGES.get(language, \"Japanese\")\n        kwargs = _sampling_kwargs(temperature, top_p)\n        wavs, sr = model_design.generate_voice_design(\n            text=text,\n            language=lang,\n            instruct=instruct_text,\n            **kwargs,\n        )\n        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n        sf.write(tmp.name, wavs[0], sr)\n        return tmp.name\n    except Exception as e:\n        raise gr.Error(f\"エラー: {e}\")\n\n\n# --- 辞書管理用ヘルパー ---\ndef _dict_to_table():\n    dic = _load_dictionary()\n    if not dic:\n        return []\n    return [[k, v] for k, v in dic.items()]\n\ndef _add_entry(word, reading):\n    if not word.strip() or not reading.strip():\n        return _dict_to_table(), \"元の表記と読み替えの両方を入力してください\"\n    dic = _load_dictionary()\n    dic[word.strip()] = reading.strip()\n    _save_dictionary(dic)\n    return _dict_to_table(), f\"登録: {word.strip()} → {reading.strip()}\"\n\ndef _del_entry(word):\n    if not word.strip():\n        return _dict_to_table(), \"削除する元の表記を入力してください\"\n    dic = _load_dictionary()\n    if word.strip() in dic:\n        del dic[word.strip()]\n        _save_dictionary(dic)\n        return _dict_to_table(), f\"削除: {word.strip()}\"\n    return _dict_to_table(), f\"「{word.strip()}」は辞書に未登録です\"\n\n\n# --- Gradio UI (スマホ対応) ---\nwith gr.Blocks(\n    title=\"Qwen3-TTS ボイスクローン\",\n    theme=gr.themes.Soft(primary_hue=\"blue\", neutral_hue=\"slate\"),\n) as demo:\n    gr.Markdown(\"# Qwen3-TTS 音声生成\")\n    gr.Markdown(f\"モデル: **{MODEL_SIZE}** | GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n\n    # === ボイスクローンタブ (最初に表示) ===\n    with gr.Tab(\"ボイスクローン\"):\n        gr.Markdown(\"**mp3/wavをアップ → テキストを入力 → その声で喋る**\")\n\n        clone_ref_audio = gr.Audio(\n            label=\"① 参照音声をアップロード (3秒以上のmp3/wav)\",\n            type=\"filepath\",\n        )\n        clone_ref_text = gr.Textbox(\n            label=\"② 参照音声のテキスト (音声で何と言っているか)\",\n            placeholder=\"例: こんにちは、今日はいい天気ですね。\",\n            lines=2,\n        )\n\n        gr.Markdown(\"---\")\n\n        clone_text = gr.Textbox(\n            label=\"③ 読み上げたいテキスト (この声で喋らせたい内容)\",\n            placeholder=\"クローンした声で読み上げたいテキストを入力...\",\n            lines=4,\n            value=\"こんにちは。この声は、アップロードされた音声からクローンされたものです。いかがでしょうか？\",\n        )\n        clone_lang = gr.Dropdown(\n            choices=list(LANGUAGES.keys()),\n            value=\"日本語\",\n            label=\"言語\",\n        )\n        with gr.Accordion(\"生成設定\", open=False):\n            clone_temp = gr.Slider(\n                minimum=0.1, maximum=1.0, value=0.7, step=0.05,\n                label=\"Temperature（低い=安定、高い=表現豊か）\",\n            )\n            clone_top_p = gr.Slider(\n                minimum=0.5, maximum=1.0, value=0.85, step=0.05,\n                label=\"Top-P（低い=安定、1.0=制限なし）\",\n            )\n            clone_seed = gr.Number(\n                value=-1, precision=0,\n                label=\"シード（-1=ランダム、0以上=固定で再現可能）\",\n            )\n        clone_btn = gr.Button(\"クローン音声を生成\", variant=\"primary\", size=\"lg\")\n        clone_output = gr.Audio(label=\"生成結果\", type=\"filepath\")\n\n        clone_btn.click(\n            voice_clone,\n            [clone_text, clone_lang, clone_ref_audio, clone_ref_text,\n             clone_temp, clone_top_p, clone_seed],\n            clone_output,\n        )\n\n    # === TTS読み上げタブ ===\n    with gr.Tab(\"TTS 読み上げ\"):\n        gr.Markdown(\"プリセット音声でテキストを読み上げます\")\n\n        tts_text = gr.Textbox(\n            label=\"テキスト\",\n            placeholder=\"読み上げたいテキストを入力...\",\n            lines=5,\n            value=\"こんにちは。Qwen3-TTSのテストです。日本語の読み上げはいかがでしょうか？\",\n        )\n        with gr.Row():\n            tts_speaker = gr.Dropdown(\n                choices=SPEAKERS,\n                value=\"Ono_Anna\",\n                label=\"音声\",\n            )\n            tts_lang = gr.Dropdown(\n                choices=list(LANGUAGES.keys()),\n                value=\"日本語\",\n                label=\"言語\",\n            )\n        with gr.Accordion(\"生成設定\", open=False):\n            tts_temp = gr.Slider(\n                minimum=0.1, maximum=1.0, value=0.7, step=0.05,\n                label=\"Temperature（低い=安定、高い=表現豊か）\",\n            )\n            tts_top_p = gr.Slider(\n                minimum=0.5, maximum=1.0, value=0.85, step=0.05,\n                label=\"Top-P（低い=安定、1.0=制限なし）\",\n            )\n            tts_seed = gr.Number(\n                value=-1, precision=0,\n                label=\"シード（-1=ランダム、0以上=固定で再現可能）\",\n            )\n        tts_btn = gr.Button(\"音声を生成\", variant=\"primary\", size=\"lg\")\n        tts_output = gr.Audio(label=\"生成結果\", type=\"filepath\")\n\n        tts_btn.click(\n            tts_generate,\n            [tts_text, tts_speaker, tts_lang, tts_temp, tts_top_p, tts_seed],\n            tts_output,\n        )\n\n    # === ボイスデザインタブ (1.7Bのみ) ===\n    if model_design is not None:\n        with gr.Tab(\"ボイスデザイン\"):\n            gr.Markdown(\"自然言語で声質を指定して音声を生成します\")\n\n            design_text = gr.Textbox(\n                label=\"読み上げテキスト\",\n                placeholder=\"読み上げたいテキスト...\",\n                lines=4,\n                value=\"今日はいい天気ですね。散歩に行きましょう。\",\n            )\n            design_lang = gr.Dropdown(\n                choices=list(LANGUAGES.keys()),\n                value=\"日本語\",\n                label=\"言語\",\n            )\n            design_desc = gr.Textbox(\n                label=\"声質の説明 (英語推奨)\",\n                placeholder=\"例: A young Japanese woman with a gentle and warm voice\",\n                lines=3,\n                value=\"A young Japanese woman with a gentle and warm voice, speaking clearly and naturally.\",\n            )\n            with gr.Accordion(\"生成設定\", open=False):\n                design_temp = gr.Slider(\n                    minimum=0.1, maximum=1.0, value=0.7, step=0.05,\n                    label=\"Temperature（低い=安定、高い=表現豊か）\",\n                )\n                design_top_p = gr.Slider(\n                    minimum=0.5, maximum=1.0, value=0.85, step=0.05,\n                    label=\"Top-P（低い=安定、1.0=制限なし）\",\n                )\n                design_seed = gr.Number(\n                    value=-1, precision=0,\n                    label=\"シード（-1=ランダム、0以上=固定で再現可能）\",\n                )\n            design_btn = gr.Button(\"デザイン生成\", variant=\"primary\", size=\"lg\")\n            design_output = gr.Audio(label=\"生成結果\", type=\"filepath\")\n\n            design_btn.click(\n                voice_design,\n                [design_text, design_lang, design_desc,\n                 design_temp, design_top_p, design_seed],\n                design_output,\n            )\n\n    # === 読み替え辞書タブ ===\n    with gr.Tab(\"読み替え辞書\"):\n        gr.Markdown(\n            \"イントネーションや読みがおかしい単語を登録すると、\"\n            \"TTS 生成前に自動で置換されます。\\n\\n\"\n            \"例: `AWS` → `エーダブリューエス` / `齟齬` → `そご`\"\n        )\n\n        dict_table = gr.Dataframe(\n            headers=[\"元の表記\", \"読み替え\"],\n            datatype=[\"str\", \"str\"],\n            value=_dict_to_table,\n            label=\"登録済み辞書\",\n            interactive=False,\n            row_count=(1, \"dynamic\"),\n        )\n\n        with gr.Row():\n            dict_word = gr.Textbox(label=\"元の表記\", placeholder=\"例: AWS\")\n            dict_reading = gr.Textbox(label=\"読み替え\", placeholder=\"例: エーダブリューエス\")\n        with gr.Row():\n            dict_add_btn = gr.Button(\"追加 / 更新\", variant=\"primary\")\n            dict_del_btn = gr.Button(\"削除\", variant=\"stop\")\n\n        dict_status = gr.Textbox(label=\"結果\", interactive=False)\n\n        dict_add_btn.click(_add_entry, [dict_word, dict_reading], [dict_table, dict_status])\n        dict_del_btn.click(_del_entry, [dict_word], [dict_table, dict_status])\n\n        gr.Markdown(\"---\")\n        gr.Markdown(\n            \"**ヒント**: 辞書は `tts_dictionary.json` に保存されます。\"\n            \"テキストエディタで直接編集も可能です。\"\n        )\n\n    gr.Markdown(\"---\")\n    gr.Markdown(\"Powered by [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) | 無料 Google Colab T4 GPU\")\n\n# 起動 (share=True で公開URLを発行 → スマホからアクセス可能)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Gradio UI を起動中...\")\nprint(\"下に表示される https://xxxxx.gradio.live の URL をタップしてください\")\nprint(\"=\"*60 + \"\\n\")\ndemo.launch(share=True, quiet=False)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 使い方\n\n1. 上のセルを実行すると `https://xxxxx.gradio.live` のような URL が表示されます\n2. その URL をスマホのブラウザで開く\n\n### ボイスクローン（メイン機能）\n1. **① 参照音声をアップロード**: スマホで録音したmp3/wavファイル（3秒以上）\n2. **② 参照テキスト**: その音声で何と言っているかを入力\n3. **③ 読み上げテキスト**: クローンした声で喋らせたい内容を入力\n4. 「クローン音声を生成」ボタンを押す\n\n### TTS読み上げ\n- テキストを入力して音声を選ぶだけ（日本語なら **Ono_Anna** がおすすめ）\n\n### ボイスデザイン (1.7Bのみ)\n- 英語で声質を指定: 「A young woman with soft voice」のように記述\n\n### プリセット音声の特徴\n| 音声 | 特徴 |\n|------|------|\n| Ono_Anna | 女性・日本語向け |\n| Vivian | 女性・英語ネイティブ風 |\n| Serena | 女性・落ち着いたトーン |\n| Dylan | 男性・英語ネイティブ風 |\n| Eric | 男性・低音 |\n| Ryan | 男性・ニュースキャスター風 |\n| Aiden | 男性・若者風 |\n\n### 注意事項\n- Colabの無料枠ではGPU使用時間に制限があります\n- 公開URLは72時間で失効します\n- セッションが切れたら再実行してください"
  }
 ]
}